

<!DOCTYPE html>
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7 ie" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8 ie" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9 ie" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1">
	<title>0.  Dissertation Outline: </title>
	<meta name="author" content="Laurel Lord">
	<link href='/assets/themes/the-program/css/style.css' rel="stylesheet" media="all">
	<link href="http://feeds.feedburner.com/" rel="alternate" title="0.  Dissertation Outline: " type="application/atom+xml">
	<script src="http://cdnjs.cloudflare.com/ajax/libs/modernizr/2.0.6/modernizr.min.js"></script>
</head>
<body>

<div id="page" class="hentry">
	<header class="the-header">
		<div class="unit-head">
			<div class="unit-inner unit-head-inner">
				<nav class="nav-global">
					<ul>
						<li class="logo"><a href="/">Laurel's Works in Progress</a></li>
						<li class="archive"><a href="/archive.html">archive</a></li>
						<li class="page"><a href="/pages.html">pages</a></li>
						<li class="category"><a href="/categories.html">categories</a></li>
						<li class="tag"><a href="/tags.html">tags</a></li>
						<li class="forkme"><div><iframe src="http://markdotto.github.com/github-buttons/github-btn.html?user=plusjade&repo=jekyll-bootstrap&type=fork&count=true"
									allowtransparency="true" frameborder="0" scrolling="0" width="95px" height="20px"></iframe></div></li>
					</ul>
				</nav>
			</div><!-- unit-inner -->
		</div><!-- unit-head -->
	</header>
	<div class="body" role="main">
		<div class="unit-body">
			<div class="unit-inner unit-body-inner">
				<div class="entry-content">
					

<article class="unit-article layout-page">
	<div class="unit-inner unit-article-inner">
		<div class="content">
			<header>
				<div class="unit-head">
					<div class="unit-inner unit-head-inner">
						<h1 class="h2 entry-title">0.  Dissertation Outline: </h1>
					</div><!-- unit-inner -->
				</div><!-- unit-head -->
			</header>

			<div class="bd">
				<div class="entry-content">
					
<h3 id="working-title">Working title:</h3>

<p>‘Novel natural language processing (NLP) model approaches for the exploration and preservation of low-resource creole languages’.</p>

<h3 id="brief">Brief:</h3>

<p>Practical applications of natural language processing (NLP) can be demanding, particularly for low-resource languages such as most of the world’s creoles. Research of this nature is often pursued in select popular languages, and models tend to depend on supervised machine learning and demand substantial quantities of annotated data for the subsequent resources to be widely distributed and used. Additional textual challenges are associated with low-resource creole languages as one has to contend with multilingual code-switching, and plentiful word-sense disambiguation issues due to high levels of polysemy and inconsistent adherence to writing systems (especially in instances where the language is mostly orally passed on and diacritic utilization is inconsistent). Analysis issues are exacerbated by the lack of text samples across varied semantic domains/topics. There are somewhat contradictory public assumptions about the language; that while most do not have definitive facts, they believe its status to be ‘actively thriving’ while acknowledging it as ‘low-resource language’. These declarations are accepted without any comprehensive data analysis on the availability of text resources or the vitality of the langauge among the current population.</p>

<p>This thesis aims to examine information extraction and natural language understanding methods for handling low-resource situations, particularly for creoles. There will be a three-pronged approach to this dissertation; it entails data collection, data modeling, and data distribution. Here I conduct surveys on a low-resource language (to confirm its vitality), create models and tools to address needs unique to the language, and attempt to distribute the sample language text files (of various domains) to facilitate the future analysis of the creoles. I focus on the use of Saint Lucian Kwéyòl (also known as ACF) as a base language for testing. Ultimately, I hope to prove that the investigation of creoles may advance the area of NLP while simultaneously disproving the assumption that Kwéyòl is a low-resource language.</p>

<p>At the end of this endeavor, I should provide a unique creole text data compilation to the field for future study. It is believed that the expansion of corpora for low-resource languages would be an overall valuable undertaking for increasing sources of language datasets for analysis. Additionally, I should create novel tools where none existed for a low-resource language. This would also include the foundations of a machine translation engine for a particular example creole language. I will also attempt to utilize word frequencies and contexts, with semantic similarity techniques to contribute an updated vocabulary list/dictionary for this previously neglected language. I would also have used cross-lingual transfer learning to explore the boundaries of modern language detection tools and address some lingering linguistic mysteries of a low-resource language (Saint Lucian Kwéyòl). Finally, I should leverage creole languages in cross-lingual models to explore the similarities and differences among Caribbean creoles and their resource-rich lexifier languages.</p>

<h3 id="initiative-1-data-collection">Initiative 1: Data collection</h3>

<p>Project 1: (partially completed)</p>

<p>Foundational data collection on low resource language presence and utilization in its society.</p>

<p>Goal:</p>

<p>To investigate the current state of a language assumed to be low-resource and confirm its vitality using modern technology.</p>

<p>Research Questions:</p>

<p>-Are professions that inherently have high levels of critical interactions with the public, and simultaneously bear the greatest likelihood of technology usage ideal subjects for online language surveys?</p>

<p>-Of the professionals tested, what percentage consider themselves fluent in a low-resource hereditary language, and is it crucial to their professional interactions?</p>

<p>-Can typical outlines of normative data generation be applied to low-resource languages, such as creoles that are typically orally taught, without issue?</p>

<p>Data:</p>

<ol>
  <li>Survey of Saint Lucian lawyers (IRB approved and distributed via Saint Lucia Bar Association).</li>
  <li>Survey of Saint Lucian teachers (drafted and in discussions with Ministry of Education; will be attending the August 31st  Saint Lucia National Language Policy Implementation Conference).</li>
  <li>Survey of Saint Lucian law enforcement (drafted and in discussions with the Royal Saint Lucia Police Force).</li>
  <li>Survey of Saint Lucian healthcare workers and emergency services (drafted and in discussions with the St. Lucia Medical and Dental Association).</li>
  <li>Survey of Saint Lucian public (vitality survey) (drafted and in discussions with the Saint Lucia Folk Research Center, Ministry of Education, The Central Statistical Office of Saint Lucia, and the Ministry of Tourism Information, Broadcasting, Culture &amp; Creative Industries).</li>
</ol>

<h3 id="initiative-2-data-modeling-and-tool-creation">Initiative 2: Data modeling and tool creation</h3>

<p>Project 1: (partially completed)</p>

<p>Increase the vocabulary lists (of the official dictionary) by at least 10% using various NLP tools and techniques.</p>

<p>Goal:</p>

<p>To create novel NLP approaches for increasing vocabulary lists of low-resource languages (modeling and expanding the Saint Lucian Kwéyòl vocabulary texts).</p>

<p>Research Questions:</p>

<p>-How can a novel application of Zipf’s law and word frequencies be used to update the vocabulary lists of low-resource languages?</p>

<p>-How can a lexifier language (such as French) be leveraged to create a unique NLTK package tuned to a related low-resource language creole? Exploration would include preprocessing, POS tagging, word tokenization, phrase partitioning, etc.</p>

<p>-Can alpha and beta phrase parsers (tumbling frequency parser) reduce issues of polysemy and word sense disambiguation in ACF?</p>

<p>-Can informal text samples (social media discussions and Wiwords.com platform contributions) be considered viable in updating the vocabulary lists of low-resource languages; particularly creoles, where polysemy and inconsistent accent usage on digital platforms increase word sense disambiguation issues?</p>

<p>Data:</p>

<p>All collected Kwéyòl text samples including formal text samples and informal text samples</p>

<p>Project 2: (partially completed)</p>

<p>Testing current language detection and cross-lingual approaches to handling low-resource creole languages</p>

<p>Goal:</p>

<p>To utilize creoles to demonstrate the limitations of current language detection tools for the ultimate purpose of generating novel NLP models capable of estimating etymological details from cross-lingual analyses.</p>

<p>Research Questions:</p>

<p>-How can advanced NLP models be used to reduce the percentage of “vocabulary of unknown origin” to below its current 11.5% of the established Kwéyòl language (via David Frank’s works).</p>

<p>-How do current language detection tools, such as Google, Yandex, and Bing (Skype), handle low-resource languages outside of their current knowledge base, and can they be reliably used to glean any etymological details?</p>

<p>-To what extent can the use of semantic similarities (words by dimensions matrices) assist with the exploration of creole vocabulary etymology (where output vectors are then compared to main lexifier languages such as French, Spanish, and Portuguese vectors to see if there are similarities)?</p>

<p>-How can additional vocabulary items be reaped from cross-lingual analysis of Caribbean creoles bearing richer text resources; can Haitian and Guadeloupean parallel texts be effectively used to address insufficiencies of text samples for Saint Lucian Kwéyòl?</p>

<p>Data:</p>

<ol>
  <li>
    <p>David Frank’s 2001 Kwéyòl language list of ‘vocabulary of unknown origin’.</p>
  </li>
  <li>
    <p>Cross-lingual data resources from relevant main lexifier languages via publicly available parallel texts (relevant public dictionaries and public text resources such as Tatoeba, etc.)</p>
  </li>
</ol>

<p>Project 3: (partially completed)</p>

<p>Goal:</p>

<p>To explore the mutual intelligibility among related main lexifier languages, and Caribbean creoles via cross-lingual analysis.</p>

<p>Research Questions:</p>

<p>-Is the assumed ‘90% mutual intelligibility among the Antillean creoles’ still an accurate figure in light of the increased text samples for analysis?</p>

<p>-Is there any creole more mutual intelligibility to Saint Lucian Kwéyòl than that of Dominica?</p>

<p>-Is Haitian creole more mutual intelligibility to Saint Lucian Kwéyòl than Dominican?</p>

<p>Data:</p>

<ol>
  <li>
    <p>Compilation of all Saint Kwéyòl data I have encountered in my studies.</p>
  </li>
  <li>
    <p>Relevant public dictionaries and samples of other Caribbean creoles via publicly available parallel texts (via Tatoeba, etc.).</p>
  </li>
</ol>

<h3 id="initiative-3-data-distribution">Initiative 3: Data distribution</h3>

<p>Project 1: (partially completed)</p>

<p>Publication of a collection of Kwéyòl text data for future data analysis</p>

<p>Goal:</p>

<p>To publish all the unique Kwéyòl data that I have encountered in my research; this would include publicly available parallel datasets.</p>

<p>Research Questions:</p>

<p>-How can the publication of a Kwéyòl text data collection occur without copyright issues?</p>

<p>Data:</p>

<p>Compilation of all Kwéyòl data I have encountered in my studies.</p>

<ol class="bibliography"></ol>


				</div><!-- entry-content -->
			</div><!-- bd -->

			<footer class="unit-foot">
				<div class="unit-inner unit-foot-inner">
					<p class="gotop">
						<a href="#page">Back to Top</a>
					</p>
				</div>
			</footer>

		</div><!-- content -->
	</div><!-- unit-inner -->
</article>


				</div>
			</div><!-- unit-inner -->
		</div><!-- unit-body -->
	</div><!-- body -->
	<footer class="the-footer">
		<div class="unit-foot">
			<div class="unit-inner unit-foot-inner">
				<div class="misc vcard">
					<h4>about</h4>
					<ul>
						<li class="contact"><address><span class="author fn n">Laurel Lord</span> - <span class="fn email">lalord@my.harrisburgu.edu</span></address></li>
						<li class="github"><a href="http://github.com/llord1/" rel="me">github.com/llord1</a></li>
						<li class="twitter"><a href="http://twitter.com//" rel="me">twitter.com/</a></li>
						<li class="rss"><a href="http://feeds.feedburner.com/">Subscribe to RSS Feed</a></li>
					</ul>
				</div><!-- misc -->
				<p class="licence">
					Theme: <a href="http://layouts-the.me">the_minimum</a> based on <a href="http://jekyllbootstrap.com/">Jekyll-bootstrap</a>.<br>
					Powered by <a href="https://github.com/mojombo/jekyll">Jekyll</a>.
				</p>
			</div><!-- unit-foot-inner -->
		</div><!-- unit-foot -->
	</footer>
</div><!-- page -->
<script>
	(function(d, s) {
		var js, fjs = d.getElementsByTagName(s)[0], load = function(url, id) {
		if (d.getElementById(id)) {return;}
		js = d.createElement(s); js.src = url; js.id = id;
		fjs.parentNode.insertBefore(js, fjs);
		};
	load('//platform.twitter.com/widgets.js', 'tweetjs');
	// load('https://apis.google.com/js/plusone.js', 'gplus1js'); // Checkout http://j.mp/ApDgMr for usage html for this is <div class="g-plusone" data-size="medium"></div>
	// load('//connect.facebook.net/en_US/all.js#xfbml=1', 'fbjssdk'); // Checkout http://j.mp/wZw2xR for using open graph protorol html for this is <div class="fb-like" data-href="/00-Outline" data-send="false" data-layout="button_count" data-width="450" data-show-faces="false" data-font="verdana"></div>
	}(document, 'script'));
</script>
<script>
/*! A fix for the iOS orientationchange zoom bug.Script by @scottjehl, rebound by @wilto. MIT License.*/
(function(j){var i=j.document;if(!i.querySelectorAll){return}var l=i.querySelectorAll("meta[name=viewport]")[0],a=l&&l.getAttribute("content"),h=a+", maximum-scale=1.0",d=a+", maximum-scale=10.0",g=true,c=j.orientation,k=0;if(!l){return}function f(){l.setAttribute("content",d);g=true}function b(){l.setAttribute("content",h);g=false}function e(m){c=Math.abs(j.orientation);k=Math.abs(m.gamma);if(k>8&&c===0){if(g){b()}}else{if(!g){f()}}}j.addEventListener("orientationchange",f,false);j.addEventListener("deviceorientation",e,false)})(this);
</script>
  
  



</body>
</html>

